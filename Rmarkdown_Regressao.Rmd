---
title: "An√°lise de Regress√£o: Sono em Mam√≠feros"
output: html_document
date: "16-11-2025"
---
# Membros do Grupo
Carolina Penido Barcellos, Gabrielly Xavier dos Santos e Matheus Soares dos Santos de Freitas.

# Introdu√ß√£o
Este trabalho consiste em analisar o **tempo total de sono dos mam√≠feros** (`total_sleep`), buscando compreender quais vari√°veis biol√≥gicas e comportamentais explicam essa caracter√≠stica.

* **Vari√°vel Resposta (Y):** `total_sleep` (Horas totais de sono por dia).
* **Vari√°veis Explicativas (X) Consideradas:**

    * `species` ‚Äì Esp√©cie do mam√≠fero.
    * `body_wt` ‚Äì Peso corporal total do mam√≠fero (em kg).
    * `brain_wt` ‚Äì Peso do c√©rebro do mam√≠fero (em kg).
    * `life_span` ‚Äì Expectativa de vida do mam√≠fero (em anos).
    * `gestation` ‚Äì Dura√ß√£o m√©dia da gesta√ß√£o (em dias).
    * `predation` ‚Äì √çndice de probabilidade de o mam√≠fero ser predado.
        * 1 = menos prov√°vel de ser predado, 5 = mais prov√°vel de ser predado.
    * `exposure` ‚Äì √çndice de exposi√ß√£o do mam√≠fero durante o sono.
        * 1 = menos exposto (ex.: dorme em abrigo), 5 = mais exposto (ex.: dorme em local aberto).
    * `danger` ‚Äì √çndice geral de perigo enfrentado, baseado nos √≠ndices `predation` e `exposure`.
        * 1 = menor perigo, 5 = maior perigo.    
```{r setup-e-carga}
install.packages("readr")
install.packages("car")
install.packages("dplyr")
install.packages("ggplot2")
install.packages("tidyr")
library(car)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)

mammals <- read_csv("dataset/mammals.csv")
```

```{r limpeza}
mammals_clean <- mammals %>%
  drop_na(species, body_wt, brain_wt, non_dreaming, dreaming, 
          total_sleep, life_span, gestation, predation, exposure, danger)
```
# Estat√≠sticas descritivas

```{r}
summary(mammals)
```
Dado que estamso tratando de regress√£o, √© desej√°vel que nossa vari√°vel resposta siga a distribui√ß√£o normal, dado que isso aumentaria as chances dos nossos erros tamb√©m serem normais. Portanto, √© v√°lido, come√ßar analisando isso.
```{r}
print(
    ggplot(mammals_clean, aes_string('total_sleep')) +
      geom_histogram(bins = 20) +
      ggtitle(paste("Histograma de total_spleep"))
  )
```

O histograma do total_sleep mostra que os dados n√£o t√™m uma distribui√ß√£o normal ("curva de sino") e parecem ter v√°rios picos (multimodal), sugerindo que h√° subgrupos diferentes de mam√≠feros.

Isso n√£o √© um problema agora, mas refor√ßa que, depois de criar o modelo, ser√° fundamental verificar se os res√≠duos (os erros) s√£o normais, pois essa √© a suposi√ß√£o principal da regress√£o.

# Testando se h√° correla√ß√£o entre as vari√°veis explicativas (Ind√≠cio de Multicolinearidade)

```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis body_wt e brain_wt
cor.test(mammals_clean$body_wt, mammals_clean$brain_wt, method = "pearson")

```
```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis exposure e danger
cor.test(mammals_clean$exposure, mammals_clean$danger, method = "pearson")
```
```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis dreaming e non_dreaming
cor.test(mammals_clean$dreaming, mammals_clean$non_dreaming, method = "pearson")
```
```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis predation e exposure
cor.test(mammals_clean$predation, mammals_clean$exposure, method = "pearson")
```
```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis predation e danger
cor.test(mammals_clean$predation, mammals_clean$danger, method = "pearson")
```
# Correla√ß√£o entre a vari√°vel resposta e cada vari√°vel independente.

```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis total_sleep e danger
cor.test(mammals_clean$total_sleep, mammals_clean$danger, method = "pearson")
```
```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis total_sleep e exposure
cor.test(mammals_clean$total_sleep, mammals_clean$exposure, method = "pearson")
```
```{r} 
#Testando se h√° correla√ß√£o linear entre as vari√°veis total_sleep e dreaming
cor.test(mammals_clean$total_sleep, mammals_clean$dreaming, method = "pearson")
```
```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis total_sleep e non_dreaming
cor.test(mammals_clean$total_sleep, mammals_clean$non_dreaming, method = "pearson")
```

```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis total_sleep e body_wt
cor.test(mammals_clean$total_sleep, mammals_clean$body_wt, method = "pearson")
```
```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis total_sleep e brain_wt
cor.test(mammals_clean$total_sleep, mammals_clean$brain_wt, method = "pearson")
```


```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis total_sleep e predation
cor.test(mammals_clean$total_sleep, mammals_clean$predation, method = "pearson")
```


```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis total_sleep e life_span
cor.test(mammals_clean$total_sleep, mammals_clean$life_span, method = "pearson")
```

```{r}
#Testando se h√° correla√ß√£o linear entre as vari√°veis total_sleep e gestation
cor.test(mammals_clean$total_sleep, mammals_clean$gestation, method = "pearson")
```
#Heatmap de correla√ß√£o
```{r}
library(corrplot)

cor_matrix <- cor(mammals_clean |> select(-species), use = "complete.obs")

corrplot(
  cor_matrix,
  method = "color",
  type = "upper",
  tl.col = "black",
  addCoef.col = NULL,  
  number.cex = 0,    
  cl.pos = "r"          
)
```
# Histogramas das vari√°veis num√©ricas
```{r}
numeric_vars <- mammals_clean |> dplyr::select(-species)

for(col in names(numeric_vars)){
  print(
    ggplot(mammals_clean, aes_string(col)) +
      geom_histogram(bins = 20) +
      ggtitle(paste("Histograma de", col))
  )
}
```
# Boxplot das vari√°veis num√©ricas para ver outliers
```{r}
for(col in names(numeric_vars)){
  print(
    ggplot(mammals_clean, aes(y = .data[[col]])) +
      geom_boxplot() +
      ggtitle(paste("Boxplot de", col))
  )
}
```
# Regress√£o Linear M√∫ltipla

Como dreaming e non_dreaming s√£o perfeitas preditoras de total_sleep, iremos retir√°-las para gera√ß√£o do modelo.

```{r}
model_full <- lm(total_sleep ~ body_wt + brain_wt + life_span +
                   gestation + predation + exposure + danger, 
                 data = mammals_clean)
summary(model_full)
```

```{r}
library(car)
vif(model_full)
```
A partir da an√°lise dos VIFs percebemos que danger, predation,brain_wt e body_wt possuem VIFs muito altos (>10), o que indica fortes sinais de multicolinearidade problem√°tica no modelo. Portanto, iremos remover a vari√°vel com maior VIF (brain_wt), ajustar e testar o modelo novamente.

```{r}
model2 <- lm(total_sleep ~ body_wt + life_span +
                   gestation + predation + exposure + danger, 
                 data = mammals_clean)
summary(model2)
```
```{r}
vif(model2)
```

Os VIFs diminuiram significativamente, mas ainda est√£o altos para as
vari√°veis predation e danger. Iremos excluir danger e ver como o modelo
se ajusta.

```{r}
model3 <- lm(total_sleep ~ body_wt + life_span +
                   gestation + predation + exposure, 
                 data = mammals_clean)
summary(model3)
```

```{r}
vif(model3)
```
Agora os VIFs diminuiram significativamente e todos est√£o abaixo de 5, mas o R2 ajustado tamb√©m diminuiu ( caindo de **0.58**, para **0.47**), o que n√£o √© um bom sinal.

Tendo tal resultado em mente, vamso tetar modelos mais robustos para escolher as nossas vari√°veis.

# StepWise
Usa uma m√©trica chamada AIC (Crit√©rio de Informa√ß√£o de Akaike) para decidir quais vari√°veis ficam e quais saem do modelo. Quanto menor o AIC, melhor.

```{r stepwise-selection}
# Come√ßamos com o modelo completo que voc√™ j√° criou
model_full <- lm(total_sleep ~ body_wt + brain_wt + life_span +
                   gestation + predation + exposure + danger, 
                 data = mammals_clean)

# Agora, pedimos ao R para "otimizar" esse modelo
# ele vai tentar ADICIONAR e REMOVER vari√°veis
model_stepwise <- step(model_full, direction = "both")

print("--- Resultado do Modelo Otimizado (Stepwise) ---")
summary(model_stepwise)

```

Dado os resultados acima, vamos verificar o VIF do modelo.
```{r}
vif_stepwise <- vif(model_stepwise)
print(vif_stepwise)
```


# Conclus√£o StepWise 
Ainda que o R^2 ajustado do modelo tenha melhorado, inicialmente, o m√©todo em questao n√£o tratou a multicolinearidade, visto que ele foi contru√≠do para se "preocupar" com com AIC do modleo, e n√£o com o VIF. para tirar as d√∫vidas de qual o melhor modelo, rodamos uma vers√£o final do stepwise, retiando a variavel `danger` que antes estava com maior VIF, obtendo um R^2 ajustado de **0.48** (veremos logo em seguida que o LASSO foi melhor).


# LASSO
√â considerado um m√©todo mais moderno e robusto para fazer sele√ß√£o de vari√°veis, especialmente quando temos multicolinearidade. Al√©m disso, esse m√©todo funciona penalizando os coeficientes, utilizando um certo *alpha*. Para escolher o melhor par√¢metro, utilizamos **Valida√ß√£o Cruzada**.

Relembrando LASSO:
A Regress√£o LASSO (Least Absolute Shrinkage and Selection Operator) √© uma das t√©cnicas de penaliza√ß√£o mais populares. Ela encolhe os coeficientes das vari√°veis menos importantes em dire√ß√£o a zero. a caracter√≠stica especial do LASSO √© que, para um ùúÜsuficientemente grande, ele pode encolher os coeficientes de algumas vari√°veis exatamente para zero, realizando assim a sele√ß√£o de vari√°veis de forma autom√°tica.
Ela minimiza a soma dos quadrados dos erros (como na regress√£o usual), mas com uma restri√ß√£o adicional:

$$
\min_{\beta_0, \beta_1, \ldots, \beta_k} \left\{ \sum_{i=1}^{n} \left(y_i - \beta_0 - \sum_{j=1}^{k} x_{ij}\beta_j\right)^2 + \lambda \sum_{j=1}^{k} |\beta_j| \right\}
$$
O par√¢metro de penalidade ùúÜ controla a for√ßa do encolhimento.

```{r LASSO}
library(glmnet)

# 2. Preparar os dados para o glmnet
# Ele n√£o aceita a f√≥rmula "Y ~ X", ele quer Matrizes
# Criamos a matriz de preditores (X)
x <- model.matrix(total_sleep ~ body_wt + brain_wt + life_span +
                     gestation + predation + exposure + danger, 
                   data = mammals_clean)[, -1] # [, -1] remove o "intercept"

y <- mammals_clean$total_sleep

# 3. Rodar o LASSO (usando Cross-Validation para achar o 'lambda' ideal)
# alpha = 1 significa LASSO (alpha = 0 seria Ridge)
cv_lasso <- cv.glmnet(x, y, alpha = 1)
plot(cv_lasso)
# 4. Ver os resultados
print("--- Coeficientes do Modelo LASSO ---")
# Ver os coeficientes no "lambda" (penalidade) ideal
coef(cv_lasso, s = "lambda.min")
print(cv_lasso$lambda.min) 

```

```{r VIF LASSO}
model_final_lasso <- lm(total_sleep ~ gestation + danger, 
                        data = mammals_clean)
vif(model_final_lasso)
summary(model_final_lasso)
```

# Conclus√£o LASSO
O LASSO produziu um modelo final, `total_sleep ~ gestation + danger`, que √© muito mais simples (o que √© desej√°vel) e robusto. Al√©m de contar com um R^2 ajustado melhor que os anteriores.

```{r modelo ajustado}
model_final <- model_final_lasso

```

# An√°lise de Res√≠duos

A an√°lise de res√≠duos √© essencial para verificar se o modelo linear ajustado atende aos pressupostos cl√°ssicos da regress√£o: normalidade dos erros, homocedasticidade, independ√™ncia e aus√™ncia de padr√µes sistem√°ticos.

# Normal QQ-plot dos Res√≠duos
```{r}
qqPlot(model_final,
       envelope = 0.95,
       main = "QQ-Plot com Envelope de 95% de Confian√ßa")
```

```{r}
shapiro.test(residuals(model_final)) # p-valor > 0.05
```
Tendo esses dados em mente, podemos assumir que os erros seguem uma distribui√ß√£o Normal.

# Autocorrela√ß√£o entre os erros - Teste de Durbin-Watson

```{r}
car::durbinWatsonTest(model_final, max.lag = 1)
```
Como o p-valor √© menor do que 0.05, rejeitamos H0 e supomos que h√° correla√ß√£o entre os erros, mas n√£o muito forte pois a estat√≠stica de teste D est√° pr√≥xima de 2.

Relembrando:
‚Ä¢ ùê∑ ‚âà 2: N√£o h√° autocorrela√ß√£o.
‚Ä¢ ùê∑ ‚âà 0: Autocorrela√ß√£o positiva.
‚Ä¢ ùê∑ ‚âà 4: Autocorrela√ß√£o negativa.
 
# Res√≠duos VS Valores Ajustados
```{r}
par(mfrow = c(1,1))
plot(model_final, which = 1)
```
A linha forma uma curva.
‚Üí existe n√£o-linearidade ‚Üí o modelo linear n√£o est√° capturando bem a rela√ß√£o.

A largura dos pontos varia ao longo da linha horizontal em y=0.
‚Üí h√° ind√≠cios de heterocedasticidade.

# Teste de Heterocedasticidade (Breusch-Pagan)
```{r}
install.packages("lmtest")
library(lmtest)
bptest(model_final)
```
O p-valor √© menor do que 0.05 , ent√£o a um n√≠vel de 5% de signific√¢ncia rejeitamos H0 e consideramos que o modelo apresenta heterocedasticidade.

Tendo esses resultados em mente, o ideal √© fazermos uma transforma√ß√£o de vari√°veis.

Uma medida corretiva comum para a n√£o-normalidade e/ou vari√¢ncia n√£o-constante √© transformar a vari√°vel resposta Y,
criando uma nova vari√°vel Y*.

# Transforma√ß√£o de Box-Cox

```{r}
install.packages("MASS")
library(MASS)

#Achando o lambda ideal
box <- boxcox(model_final, plotit = TRUE)
lambda <- box$x[which.max(box$y)]
lambda
#Transformar y:
if (abs(lambda) < 1e-6) {
  y_trans <- log(mammals_clean$total_sleep)
} else {
  y_trans <- (mammals_clean$total_sleep^lambda - 1)/lambda
}

#verificar se o modelo est√° melhor
model_box <- lm(y_trans ~ gestation + danger, data = mammals_clean)
qqPlot(model_box,
       envelope = 0.95,
       main = "QQ-Plot com Envelope de 95% de Confian√ßa")
bptest(model_box)
dwtest(model_box)
```

```{r}
par(mfrow = c(1,1))
plot(model_box, which = 1)
```
```{r}
shapiro.test(residuals(model_box)) # p-valor > 0.05
```
# Conclus√£o Geral da Transforma√ß√£o Box-Cox
Heterocedasticidade: RESOLVIDA

Normalidade: ERROS CONTINUAM SEGUINDO DISTRIBUI√á√ÉO NORMAL

(Transforma√ß√£o Box‚ÄìCox ajudou)

Autocorrela√ß√£o dos res√≠duos: AINDA PRESENTE